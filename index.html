---
layout: default
---

<div>

	Estos apuntes son una traducción de los originales en inglés que se pueden encontrar <a href="https://cs231n.github.io">aquí</a>. Son un suplemento del curso de Stanford CS <a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a>. 
  <br>
  Si tiene alguna pregunta o sugerencia sobre la traducción puede contactar con la <a href="https://esparig.github.io">autora</a>. 
  Si tiene alguna pregunta, sugerencia, o quiere informar sobre algún bug en las tareas contacte (en inglés) con <a href="http://cs.stanford.edu/people/jcjohns/">Justin Johnson</a> o bien, si es acerca delos apuntes originales, contacte con <a href="http://cs.stanford.edu/people/karpathy/">Andrej Karpathy</a>. También puede, si lo desea, solicitar un pull request directamente al repositorio <a href="https://github.com/cs231n/cs231n.github.io">git repo</a>.
  <br>
  Os animamos a utilizar la extensión <a href="https://hypothes.is/">hypothes.is</a> para anotar los comentarios y poder discutir acerca de los apuntes entre líneas.
</div>

<div class="home">
  <div class="materials-wrap">
    <div class="module-header">Tareas Primavera 2019</div>

    <div class="materials-item">
      <a href="assignments2019/assignment1/">
        Tarea #1: Clasificación de Imágenes, kNN, SVM, Softmax, Red Neuronal
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2019/assignment2/">
        Tarea #2: Redes Fully-Connected, Batch Normalization, Dropout,
        Redes Convolucionales
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2019/assignment3/">
        Assignment #3: Nombrado de Imágenes mediante Vanilla RNNs, y mediante LSTMs, 
	Visualización de Redes, Transferencia de Estilo, Redes GAN (Generative Adversarial Networks)
      </a>
    </div>
    <!--
    <div class="module-header">Spring 2018 Assignments</div>

    <div class="materials-item">
      <a href="assignments2018/assignment1/">
        Assignment #1: Image Classification, kNN, SVM, Softmax, Neural Network
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2018/assignment2/">
        Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout,
        Convolutional Nets
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2018/assignment3/">
        Assignment #3: Image Captioning with Vanilla RNNs, Image Captioning 
	with LSTMs, Network Visualization, Style Transfer, Generative Adversarial Networks
      </a>
    </div>
    -->
	  
    <!--
    <div class="module-header">Winter 2016 Assignments</div>

    <div class="materials-item">
      <a href="assignments2016/assignment1/">
        Assignment #1: Image Classification, kNN, SVM, Softmax, Neural Network
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2016/assignment2/">
        Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout,
        Convolutional Nets
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2016/assignment3/">
        Assignment #3: Recurrent Neural Networks, Image Captioning,
        Image Gradients, DeepDream
      </a>
    </div>
    -->
	  
    <!--
    <div class="module-header">Winter 2015 Assignments</div>

    <div class="materials-item">
      <a href="assignment1/">
        Assignment #1: Image Classification, kNN, SVM, Softmax
      </a>
    </div>

    <div class="materials-item">
      <a href="assignment2/">
        Assignment #2: Neural Networks, ConvNets I
      </a>
    </div>

    <div class="materials-item">
      <a href="assignment3/">
        Assignment #3: ConvNets II, Transfer Learning, Visualization
      </a>
    </div>
  -->

    <div class="module-header">Módulo 0: Preparación</div>

    <div class="materials-item">
      <a href="setup-instructions/">
        Instalación y Configuración
      </a>
    </div>

    <div class="materials-item">
      <a href="python-numpy-tutorial/">
        Tutorial Python / Numpy
      </a>
    </div>

    <div class="materials-item">
      <a href="ipython-tutorial/">
       Tutorial IPython Notebook
      </a>
    </div>
<!--
    <div class="materials-item">
      <a href="terminal-tutorial/">
        Terminal.com Tutorial
      </a>
    </div>
-->
    <div class="materials-item">
      <a href="https://github.com/cs231n/gcloud">
        Tutorial Google Cloud
      </a>
    </div>
    <div class="materials-item">
      <a href="aws-tutorial/">
        Tutorial AWS
      </a>
    </div>

	 <!-- hardcoding items here to force a specific order -->
    <div class="module-header">Módulo 1: Redes Neuronales</div>
    <div class="materials-item">
      <a href="classification/">
        Clasificación de Imágenes: Enfoque basado en Datos, k-Vecinos más cercanos, datos de entrenamiento/validación/test
      </a>
      <div class="kw">
        L1/L2 distances, hyperparameter search, cross-validation
      </div>
    </div>

    <div class="materials-item">
      <a href="linear-classify/">
         Clasificación lineal: SVM (Support Vector Machine), "Softmax"
      </a>
      <div class="kw">
        parameteric approach, bias trick, hinge loss, cross-entropy loss, L2 regularization, web demo
      </div>
    </div>

    <div class="materials-item">
      <a href="optimization-1/">
        Optimización: Stochastic Gradient Descent
      </a>
      <div class="kw">
        optimization landscapes, local search, learning rate, analytic/numerical gradient
      </div>
    </div>

    <div class="materials-item">
      <a href="optimization-2/">
        Intuición sobre "Backpropagation"
      </a>
      <div class="kw">
        chain rule interpretation, real-valued circuits, patterns in gradient flow
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-1/">
          Redes Neuronales Parte 1: Configurar una Arquitectura
      </a>
      <div class="kw">
        model of a biological neuron, activation functions, neural net architecture, representational power
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-2/">
          Redes Neuronales Parte 2: Datos y Función de Pérdida
      </a>
      <div class="kw">
          preprocessing, weight initialization, batch normalization, regularization (L2/dropout), loss functions
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-3/">
        Redes Neuronales Parte 3: Aprendizaje y Evaluación
      </a>
      <div class="kw">
        gradient checks, sanity checks, babysitting the learning process, momentum (+nesterov), second-order methods, Adagrad/RMSprop, hyperparameter optimization, model ensembles
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-case-study/">
          Caso de estudio: Una Red Neuronal Mínima
      </a>
      <div class="kw">
        minimal 2D toy data example
      </div>
    </div>

    <div class="module-header">Módulo 2: Redes Neuronales Convolucionales</div>

    <div class="materials-item">
      <a href="convolutional-networks/">
        Redes Neuronales Convolucionales: Arquitecturas, Convolución, Capas "Pooling"
      </a>
      <div class="kw">
          layers, spatial arrangement, layer patterns, layer sizing patterns, AlexNet/ZFNet/VGGNet case studies, computational considerations
      </div>
    </div>

    <div class="materials-item">
      <a href="understanding-cnn/">
        Comprender y Visualizar Redes Neuronales Convolucionales
      </a>
      <div class="kw">
        tSNE embeddings, deconvnets, data gradients, fooling ConvNets, human comparisons
      </div>
    </div>

    <div class="materials-item">
      <a href="transfer-learning/">
        Transferencia de Aprendizaje, y "Fine-tuning" de Redes Neuronales Convolucionales
      </a>
    </div>
 
  </div>
</div>
